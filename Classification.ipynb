{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMiller113/Machine_Learning/blob/master/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51BuGjrftO6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bf16d3e6-53cb-4aeb-a484-fa33299666a2"
      },
      "source": [
        "!pip install -q tensorflow==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 87.9MB 67kB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 61.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 22.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqnLGwd4ZHug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split # Can be used to create a validation set from the training data\n",
        "from sklearn.preprocessing import StandardScaler # Can be used to standardize the inputs\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9aeTOmVZgei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_breast_cancer() # data is of type bunch, the values in the bunch however are all ndarrays\n",
        "x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33) # returns a 4 element tuple\n",
        "N, D = x_train.shape # Shape is an attribute\n",
        "scaler = StandardScaler() # Scaler object must be instantiated\n",
        "x_train = scaler.fit_transform(x_train) # Fit generates mu/mean and sigma/stdev, transform warps the dataset\n",
        "x_test = scaler.transform(x_test) # Using the same paremeters generated by fit_transform we transform the test set "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVvkrz0gxUK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential( # Sequentially activate the list of keras layer functopns\n",
        "    [tf.keras.layers.Input(shape=(D,)), # Passes the shape of the input vector to Keras\n",
        "     tf.keras.layers.Dense(1, activation='sigmoid') # Dense computes the activation function for the model, the output size and the activation function to be used are the required arguments\n",
        "     ])\n",
        "model.compile(optimizer='adam', # The gradient descent optimizer function, adam is the general use case function\n",
        "                  loss='binary_crossentropy', # There are two labels in the data set so we must use binary cross entropy for the loss function\n",
        "                  metrics=['accuracy']) # Tells the model what metrics to keep track of while training takes place\n",
        "r = model.fit(x_train,y_train, validation_data=(x_test,y_test),epochs=100) # trains the model, saves the history to r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iVw-nZEEpuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train Score:', model.evaluate(x_train, y_train)) # Shows the training score\n",
        "print('Test Score:', model.evaluate(x_test,y_test)) # Shows the test score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5T5ym0ICKXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(r.history['loss'], label='Loss') #plots the training loss data\n",
        "plt.plot(r.history['val_loss'], label='Val_Loss') # plots the validation loss data\n",
        "plt.legend()\n",
        "plt.show() # shows the graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjiPzOeyHazY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(r.history['accuracy'], label = 'acc')\n",
        "plt.plot(r.history['val_accuracy'], label= 'val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}